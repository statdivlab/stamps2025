---
title: "Regression: fitting and interpretation"
author: "Amy Willis, Sarah Teichman and Maria Valdez"
date: "2025-07-21"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

In this lab, we'll practice running linear regression with the functions `lm` and `regress`. 
We'll also manipulate our data with the functions from the `tidyverse` and plot our data with `ggplot`.

WARNING!!: There will be a few intentional errors here for you to fix (so you can practice debugging!). If a line of code isn't working, think about how you can fix it to make it work. 

## Loading Data

Let's begin by loading in the tidyverse, which we'll need for this tutorial.

```{r}
library(tidyverse)
```

Next, let's load our data. We'll start with two data sets. This data comes from a study of people living with cystic fibrosis. It consists of 16S and droplet digital PCR (ddPCR) data from both saliva and sputum (coughed up mucus) from study participants. More information can be found here: 
https://journals.asm.org/doi/full/10.1128/mSystems.00296-20?rfr_dat=cr_pub++0pubmed&url_ver=Z39.88-2003&rfr_id=ori%3Arid%3Acrossref.org&

```{r}
ddpcr <- read_csv("https://raw.githubusercontent.com/statdivlab/stamps2024/main/stats-labs/lm-lab/data/ddPCR.csv")
meta <- read_csv("https://raw.githubusercontent.com/statdivlab/stamps2024/main/stats-labs/lm-lab/data/meta_data.csv")
```

## Preparing the data

We can take a look at the beginning of each dataset with the function head

```{r}
head(dpcr)
head(meta)
```

We'd like to combine these two data sets together. They both contain the variable `sample_name`, so we will match observations based on this variable. `inner_join` combines these two datasets into a single one, cleverly using the `by` argument to figure out how to rows match up. 

Note that when we use `tidyverse` syntax, the pipe symbol %>% is our friend. The pipe lets us chain commands together, using the output of the previous command as the input to the next command. 

```{r}
both <- meta %>% 
  inner_join(ddpcr, by = "sample_name") 
```

Next, we will manipulate our data to make it easier to work with. We'll rename the variable `Average Replicates, stock DNA (copies /µl)` (remember, we like variable names to be concise and avoid spaces) and tell R that this variable is a number (removing the commas in the process). 

We'll define FEV1 to be a numeric variable as well.

```{r}
both <- both %>%
  rename(ddpcr = `Average Replicates, stock DNA (copies /µl)`) %>%
  mutate(ddpcr = gsub(",", "", ddpcr)) %>%
  mutate(ddpcr = as.numeric(ddpcr)) %>%
  mutate(FEV1 = as.numeric(FEV1)) 
```
The last line guarantees `Subject ID` (which is originally a string variable ordered by alphabetical order), is a categorical variable sorted by its numerical value. 

**Optional exercise:** Later in this lab, we will visualize our data using various plots where Subject ID is utilized as a color variable. Subject ID is a categorical variable that can only take a value from a finite set of options (1, 2, 3, ..., 10). However, it is currently sorted alphabetically, causing ID 10 to appear before 2, 3, ..., 9. To correct this, you can modify the variable in the table by converting it to numeric for proper sorting (using `as.numeric`) and then back to a categorical variable (using `factor`). Complete the code below to perform this modification before proceeding to the plotting section. 

```{r}
both <- both %>%
  mutate(`Subject ID` = _____(______(`Subject ID`))) 
```

You can run each of these lines individually to further explore what each command is doing. 

## Exploring the Data

Earlier we looked at the first few observations of each dataset. To see a full list of variables in our dataset, we can use the `names()` function.

```{r}
names(both)
```

We'll be focusing on a few variables from this dataset: ddpcr, FEV1, Treatment Group, Sample Type, and Subject ID. 

- ddpcr: droplet digital PCR, giving the observed total bacterial load in the sample in copies/uL
- FEV1: Forced expiratory volume (FEV) measures how much air a person can exhale during a forced breath (L/s)
- Treatment Group: "ON" if the sample is from a subject receiving antibiotics, "OFF" otherwise 
- Sample Type: the body site of origin of the sample, either saliva or sputum
- Subject ID: an ID identifying the participant 

Before we do inference, we should plot our data. This lets us get a sense of general trends and build intuition about our data. 

We'll use `ggplot` for plotting. Remember that in `ggplot` we start with the base of our plot, where we specify our dataset and variables, and then we can build up our plot by adding layers with the `+` operator. We'll build this first plot step by step.

```{r}
ggplot(data = both, aes(x = `Sample Type`, y = ddpcr, col = `Subject ID`))
```

This sets up our axis labels. We are now ready to add a plotting layer.

```{r}
ggplot(data = both, aes(x = `Sample Type`, y = ddpcr, col = `Subject ID`)) +
  geom_jitter(height = 0, width = 0.3)
```

`geom_jitter` is a great way to make a scatter plot with a categorical variable on the x-axis. It spreads the points out so that they do not all line up exactly for the same values of x. You can change the width value to see how it changes the appearance of the plot.

We like to add informative labels with the `labs` layer to improve on our variable names. Select proper names for the y-axis and the title of the plot below (don't forget to use quotation marks!):

```{r}
ggplot(data = both, aes(x = `Sample Type`, y = ddpcr, col = `Subject ID`)) +
  geom_jitter(height = 0, width = 0.3) + 
  labs(y = ,
       title = )
```


`ggplot` by default left-justifies titles. The theme layer centers the title. Add `theme(plot.title = element_text(hjust = 0.5))` to improve the look of your plot above.

The ddpcr data is skewed, with a few larger outliers taking up a lot of space on our plot. We can transform ddpcr to the log of ddpcr to visualize this in a  different way.

```{r}
ggplot(data = both, aes(x = `Sample Type`, y = ddpcr, col = `Subject ID`)) +
  geom_jitter(height = 0, width = 0.3) + 
  labs(y = "",
       title = "") + 
  scale_y_log10()
```

What do we learn from this plot? 

It seems that there are sputum samples generally have higher concentration (ddPCR) values than saliva samples.

```{r}
ggplot(data = both, aes(x = `Treatment Group`, y = ddpcr, col = `Subject ID`)) 
  geom_jitter(height = 0, width = 0.3) +
  labs(y = "Average observed ddPCR\n(copies/ul)",
       title = "Digital PCR by Treatment") + 
  scale_y_log10() + 
  theme(plot.title = element_text(hjust = 0.5))
```

What do we learn from this plot? 

There are a lot more non-treated samples than treated samples. The general trend seems to be higher observed concentration values from non-treated samples than treated samples.

```{r}
ggplot(data = both, aes(x = as.numeric(FEV1), y = ddpcr, col = `Subject ID`)) +
  geom_point() + 
  labs(x = "FEV Value",
       y = "Average observed ddPCR\n(copies/ul)",
       title = "Digital PCR by FEV Value") + 
  scale_y_log10() +
  theme(plot.title = element_text(hjust = 0.5))
```

What do we learn from this? 

There might be a slight negative correlation between concentration values and FEV values
There seem to be two observations for each value on the x-axis. Why might that be?

It turns out, saliva and sputum samples are paired (one each for each subject), and so share a value of FEV1! Whoops - we forgot about this - or maybe the postdoc left and we weren't told. 

Insights like this from our plot might lead us to analyze our data. 

## Fitting regression models

Now, let's look at the association between digital PCR measurements and whether the sample is from saliva or sputum. We'll use the `lm` command. 
  
Note that by fitting a linear model, we are targeting a parameter that represents differences in means. We could also choose to target a parameter that represents fold-differences in means. We'll see an example of this at the end of the lab. Either option is valid, as long as you correctly interpret the coefficients in terms of the model that you've chosen. The decision about which model to choose should be motivated by your preferred interpretation of your results: "Would I rather say that the outcome is B units higher, or C percent higher?" (Recall the discussion from lecture.)

We use `lm` to fit the linear model. 

```{r}
mod_type <- lm(ddpcr ~ `Sample Type`, data = both)
summary(mod_type)
```

Notice the syntax we use here. The first argument is called a formula. It takes the form "response variable ~ predictor variable". The second argument specifies the dataset that contains the variables you are using. 

We use ` ` around the variable name `Sample Type` because it has a space in it. This is another good reason not to have spaces in your variable names! 

To look at the results of our model, we can use the function `summary`

How do we interpret the previous output? 

We have two rows in the "Coefficients" table. The first row refers to the "intercept" of our model (the estimate if all covariates equal zero). The following rows correspond with covariates. Let's walk through them. 

We have 4 columns. The first column gives the estimate of the parameter, and the second column gives its standard error (remember, this is an estimate of the standard deviation of our estimate). 

`lm` will by default test the hypothesis that the coefficient for each covariate is equal to 0. If this hypothesis is rejected, we conclude that there is an association between our covariate and outcome (after accounting for other covariates). The third column of our output gives the test statistic for that hypothesis test, and the fourth column gives a p-value. 

What does the second row of the output tell us? 

Our estimate of 1,006,955 for the coefficient for `Sample Type`Sputum tells us that the estimated mean ddPCR measurement for a sample of sputum is 1,000,955 counts/uL higher than the estimated mean ddPCR measurement for a sample from saliva. 

We have a p-value of 0.01. If we use a alpha level of 0.05, we reject the null hypothesis that there is no difference in the true mean concentration in sputum and saliva samples. 

Now, let's fit a model with multiple covariates. Let's consider `Treatment Group` and `Sample Type`. Write the proper model below, using `+` to connect covariates

```{r}
mod_treat_type <- lm(ddpcr ~ , data = both)
summary(mod_treat_type)
```

How would we interpret these results? 

Here, we have a significant difference in average DNA copies/ml across sample types (at the alpha=0.05 level), but not across treatment groups. 

What if we think there is an interaction between the effects of treatment and sample type on ddpcr? i.e., a **different difference** in bacterial load ON compared to OFF treatment for Sputum and Saliva biomes. 

We can fit an interaction model by replacing the `+` above with `*`.

```{r}
mod_interact <- lm(both, ddpcr ~ Sample Type * Treatment Group)
summary(mod_interact)
```

Now we have an extra row. Not only do we have rows for `Sample Type`Sputum and Treatment, but we also have an interaction row. The estimate for the interaction can be interpreted as the following: 

-349,375 is the estimated value of the difference in mean bacterial concentration in sputum for people on antibiotics compared to people not on antibiotics minus the difference in mean bacterial concentration in saliva for people on antibiotics compared to people not on antibiotics.

Note that our estimates and standard errors for `Sample Type`Sputum and `Treatment Group`ON are different for our two models. This is because whenever we change something (add a covariate, add an interaction, etc) we are fitting a different model. Our strongest advice on the subject of "which model to choose?" is to be motivated by your scientific question, and consider the classification of variables presented in the lecture: predictor of interest (always include), precision variables (good to include most important ones), confounders (always include, but use the actual definition, not the way most people talk about it) and relevant effect modifiers (include if scientifically relevant)). 

If we would prefer to target a parameter that represents fold-differences in means, we can use Poisson regression. We can do this in R using the `rigr` package with the `rate` argument. While we we could use the `glm` function in the `stats` package, we like `rigr` because by default it uses robust standard errors (these are robust to certain types of model misspecification).   

```{r}
# install rigr (only if you don't already have it installed)
if (!("rigr" %in% row.names(installed.packages()))) {
  install_github("https://github.com/statdivlab/rigr")
}
library(rigr)
mod_counts_type <- regress(fnctl = "rate", formula = ddpcr ~ `Sample Type`, data = both)
coef(mod_counts_type)
```

How do we interpret these coefficients? 

By exponentiating the estimated coefficient (`exp(0.73)` = 2.08), we can say that the mean ddPCR measurement observed for samples of Sputum is 2.08 times higher than the mean ddPCR measurement for samples of saliva. A p-value of 0.01 indicates we have enough evidence to reject the hypothesis that there is no fold-difference in ddPCR measurements between sputum and saliva samples (at an alpha level of 0.05).

Now create your own model, by selecting:

1. Two covariates that you think could potentially be associated to the ddpcr counts in some scale. 

2. How are you interested in exploring these associations? 
Include your fitted model here: 

```{r}
My_own_mod <- 
  
coef(My_own_mod)
```

And then provide an interpretation on your results: 

## Using `dagify` to determine adjustment sets 

As we discussed in the lecture, drawing causal diagrams (DAGs) can help you encode your assumptions about the covariates in your data and decide which to include in your model. Here, we will work through some examples. First, we need to install the `dagitty` and `ggdag` packages (if you don't already have them) and load them.

```{r}
# install dagitty (only if you don't already have it installed)
if (!("dagitty" %in% row.names(installed.packages()))) {
  install.packages("dagitty")
}
library(dagitty)
# install ggdag (only if you don't already have it installed)
if (!("ggdag" %in% row.names(installed.packages()))) {
  install.packages("ggdag")
}
library(ggdag)
```

### Scenario 1

Let's start with the example from the slides. Imagine that you are considering the exposure of disease, the outcome of microbe abundance, and you have also measured age, diet, and antibiotic use. You believe that age causes disease and microbe abundance, diet causes disease and microbe abundance, and disease causes antibiotic use which causes microbe abundance. 

We can use `dagify` to make this DAG object in R, and then can use `adjustment_sets` to see what some reasonable adjustment sets would be for this scenario. 

```{r}
dag1 <- dagify(
  abundance ~ age + diet + disease + antibiotic, # describe all causes of microbe abundance
  disease ~ age + diet, # describe all causes of disease 
  exposure = "disease",
  outcome = "abundance"
)
# plot this DAG 
ggdag(dag1, text = FALSE) +
  theme_dag() + 
  geom_dag_label(size = 3, alpha = 0.7)
```

Now, lets use `adjustmentSets()` to look at the minimal adjustment sets, i.e. the set of covariates that we should include to avoid biasing our parameter estimates. 

```{r}
adjustmentSets(dag1, type = "minimal") 
adjustmentSets(dag1, type = "canonical") 
```

In the first call to `adjustmentSets` we use `type = "minimal"`, saying that we want the smallest set of covariates to avoid biasing our parameter estimates. This includes the two confounder covariates age and diet, but avoids the precision covariate antibiotic use. 

In the second call to `adjustmentSets` we use `type = "canonical"`, saying that we want a single set and it does not have to be the smallest one. This includes the two confounders of age and diet, as well as the precision covariate antibiotic use. 

If you were running this analysis, you could decide how complex you wanted your model to be, and whether or not you wanted to include antibiotic use. The StatDivLab would generally recommend including precision variables (here, antibiotic use) in small models, but if the model was much larger or the dataset smaller, we might only include the most important few precision variables.

### Scenario 2 

Consider a very similar situation, however now you have reason to believe that disease causes antibiotic use. Let's adjust our DAG to encode this. 

```{r}
dag2 <- dagify(
  abundance ~ age + diet + disease + antibiotic, # describe all causes of microbe abundance
  disease ~ age + diet, # describe all causes of disease 
  antibiotic ~ disease, # describe all causes of antibiotic resistance 
  exposure = "disease",
  outcome = "abundance"
)
# plot this DAG 
ggdag(dag2, text = FALSE) +
  theme_dag() + 
  geom_dag_label(size = 3, alpha = 0.7)
```

Again, lets use `adjustmentSets()` to look at the adjustment sets. 

```{r}
adjustmentSets(dag2, type = "minimal", effect = "total") 
adjustmentSets(dag2, type = "canonical", effect = "total")
adjustmentSets(dag2, type = "minimal", effect = "direct")
```

Now, the results are a little different. The argument `effect` tells us the type of effect we're looking for. `total` means that we care about the effect of disease on microbe abundance through both direct causal pathways (the single causal path from the exposure/predictor to the outcome/response) and indirect pathways (including the path from disease to antibiotic use to microbe abundance). 

It's not "better" to look at total effects, nor direct effects. They answer different scientific questions! Your research scope and questions will guide your choice here. 

If we wanted to estimate the **total effect**, we should avoid including antibiotic use in our adjustment set. Informally, accounting for it "splits" the pathway and means we can't focus on the effect of disease, like we wanted.  

However, if we want the **direct effect** (i.e. only the effect of disease on microbe abundance through the direct path, not the indirect effect through antibiotic use) then we can use `effect = "direct"`. This adjustment set does include age, diet, and antibiotic use. Including antibiotic use "blocks", or accounts for, the contribution of antibiotic usage, allowing us to target only the direct effect. 

### Scenario 3 

The growth rate of bacteria can be impacted by temperature. You heard a rumor that the expression of the cell division ftsZ gene changes based on ocean temperature, and want to study this effect. But you also know that expression of the ftsZ gene is affected by time of day. Additionally, both ocean temperature and the abundance of organisms carrying the ftsZ gene are affected by season. Ocean temperature also affects nutrient concentrations, which in turn affects the abundance of organisms carrying gene ftsZ. 

Thankfully, you collected TODO data, and have learnt some stuff about principled approaches to choosing adjustment sets. So, you can make an analysis plan to target the scientific question you care about, and account for what you know about this system. 

Use `dagify` to make a DAG object for this scenario, `ggdag` to visualize this DAG, and then `adjustmentSets()` to consider what covariates to include. You can decide what `type` of set you want, and whether you care about the direct or total `effect`. 

```{r}
dag3 <- dagify(
  # causes for one variable
  # causes for another variable 
  # causes for ...
  exposure = ,
  outcome = 
)
# plot this DAG 
ggdag(dag3, text = FALSE) +
  theme_dag() + 
  geom_dag_label(size = 3, alpha = 0.7)
# get adjustment sets
adjustmentSets(dag3, type = "...", effect = "...")
```

What set did you choose? Why?
